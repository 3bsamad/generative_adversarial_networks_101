{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCGANs - Context-Conditional Generative Adversarial Networks\n",
    "\n",
    "Introduction to Context-Conditional Generative Adversarial Networks or CCGANs.\n",
    "\n",
    "This notebook is organized follows:\n",
    "\n",
    "1. **Background**\n",
    "* **Definition**\n",
    "* **Training CCGANs with Keras and TensorFlow**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Background\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Definition\n",
    "\n",
    "![ccgan](../img/ccgan.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training CCGANs with Keras and TensorFlow\n",
    "\n",
    "CCGANs implementation using ... the [Keras](https://keras.io/) library.\n",
    "\n",
    "### 1. Load data\n",
    "\n",
    "#### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T17:17:29.299849Z",
     "start_time": "2018-06-18T17:17:28.948111Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T17:17:30.625836Z",
     "start_time": "2018-06-18T17:17:29.301825Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, LeakyReLU, BatchNormalization\n",
    "from keras.layers import Input, Flatten, Embedding, multiply, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras import initializers\n",
    "\n",
    "from keras_contrib.layers.normalization import InstanceNormalization\n",
    "from keras.layers import Concatenate, GaussianNoise\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras import losses\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "\n",
    "# from scipy.misc import imresize\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T17:17:31.211621Z",
     "start_time": "2018-06-18T17:17:30.628121Z"
    }
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore visual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T17:17:31.673570Z",
     "start_time": "2018-06-18T17:17:31.213616Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    x_y = X_train[y_train == i]\n",
    "    plt.imshow(x_y[0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Class %d\" % (i))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshaping and normalizing the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T17:17:31.926590Z",
     "start_time": "2018-06-18T17:17:31.675462Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (60000, 28, 28)\n",
      "y_train.shape (60000,)\n",
      "X_train reshape: (60000, 28, 28, 1)\n",
      "y_train reshape: (60000, 11)\n"
     ]
    }
   ],
   "source": [
    "print('X_train.shape', X_train.shape)\n",
    "print('y_train.shape', y_train.shape)\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "    input_shape = (1, 28, 28)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "    input_shape = (28, 28, 1)\n",
    "\n",
    "# the generator is using tanh activation, for which we need to preprocess \n",
    "# the image data into the range between -1 and 1.\n",
    "\n",
    "X_train = np.float32(X_train)\n",
    "X_train = (X_train / 255 - 0.5) * 2\n",
    "X_train = np.clip(X_train, -1, 1)\n",
    "\n",
    "# y to categorical\n",
    "num_classes = 10\n",
    "y_train = to_categorical(y_train, num_classes=num_classes+1)\n",
    "\n",
    "print('X_train reshape:', X_train.shape)\n",
    "print('y_train reshape:', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train reshape: (60000, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = resize(X_train, [X_train.shape[0], 32, 32, 1])\n",
    "print('X_train reshape:', X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define model\n",
    "\n",
    "#### Generator\n",
    "\n",
    "\"U-Net\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T17:17:32.266239Z",
     "start_time": "2018-06-18T17:17:31.929037Z"
    }
   },
   "outputs": [],
   "source": [
    "# # latent space dimension\n",
    "# latent_dim = 100\n",
    "\n",
    "# # imagem dimension 28x28\n",
    "# img_dim = 784\n",
    "\n",
    "init = initializers.RandomNormal(stddev=0.02)\n",
    "\n",
    "# # Generator network\n",
    "# generator = Sequential()\n",
    "\n",
    "# # Input layer and hidden layer 1\n",
    "# generator.add(Dense(128, input_shape=(latent_dim,),\n",
    "#                     kernel_initializer=init))\n",
    "# generator.add(BatchNormalization())\n",
    "# generator.add(LeakyReLU(0.2))\n",
    "\n",
    "# # Hidden layer 2\n",
    "# generator.add(Dense(256))\n",
    "# generator.add(LeakyReLU(0.2))\n",
    "# generator.add(BatchNormalization())\n",
    "\n",
    "# # Hidden layer 3\n",
    "# generator.add(Dense(512))\n",
    "# generator.add(LeakyReLU(0.2))\n",
    "# generator.add(BatchNormalization())\n",
    "\n",
    "# # Output layer \n",
    "# generator.add(Dense(img_dim, activation='tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Number of filters in first layer of generator\n",
    "gf = 32\n",
    "k = 4\n",
    "s = 2\n",
    "\n",
    "# imagem shape 28x28x1\n",
    "img_shape = X_train[0].shape\n",
    "\n",
    "# Generator input\n",
    "img_g = Input(shape=(img_shape))\n",
    "\n",
    "# Downsampling\n",
    "d1 = Conv2D(gf, kernel_size=k, strides=s, padding='same')(img_g)\n",
    "d1 = LeakyReLU(alpha=0.2)(d1)\n",
    "\n",
    "d2 = Conv2D(gf*2, kernel_size=k, strides=s, padding='same')(d1)\n",
    "d2 = LeakyReLU(alpha=0.2)(d2)\n",
    "d2 = BatchNormalization(momentum=0.8)(d2)\n",
    "\n",
    "d3 = Conv2D(gf*4, kernel_size=k, strides=s, padding='same')(d2)\n",
    "d3 = LeakyReLU(alpha=0.2)(d3)\n",
    "d3 = BatchNormalization(momentum=0.8)(d3)\n",
    "\n",
    "d4 = Conv2D(gf*8, kernel_size=k, strides=s, padding='same')(d3)\n",
    "d4 = LeakyReLU(alpha=0.2)(d4)\n",
    "d4 = BatchNormalization(momentum=0.8)(d4)\n",
    "\n",
    "# Upsampling\n",
    "u1 = UpSampling2D(size=2)(d4)\n",
    "u1 = Conv2D(gf*4, kernel_size=k, strides=1, padding='same', activation='relu')(u1)\n",
    "u1 = BatchNormalization(momentum=0.8)(u1)\n",
    "\n",
    "u2 = Concatenate()([u1, d3])\n",
    "u2 = UpSampling2D(size=2)(u2)\n",
    "u2 = Conv2D(gf*2, kernel_size=k, strides=1, padding='same', activation='relu')(u2)\n",
    "u2 = BatchNormalization(momentum=0.8)(u2)\n",
    "\n",
    "u3 = Concatenate()([u2, d2])\n",
    "u3 = UpSampling2D(size=2)(u3)\n",
    "u3 = Conv2D(gf, kernel_size=k, strides=1, padding='same', activation='relu')(u3)\n",
    "u3 = BatchNormalization(momentum=0.8)(u3)\n",
    "\n",
    "u4 = Concatenate()([u3, d1])\n",
    "u4 = UpSampling2D(size=2)(u4)\n",
    "u4 = Conv2D(1, kernel_size=4, strides=1, padding='same', activation='tanh')(u4)\n",
    "\n",
    "generator = Model(img_g, u4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator model visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T17:17:32.266239Z",
     "start_time": "2018-06-18T17:17:31.929037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 16, 16, 32)   544         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 16, 16, 32)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 8, 8, 64)     32832       leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 8, 8, 64)     0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 8, 8, 64)     256         leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 4, 4, 128)    131200      batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 4, 4, 128)    0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 4, 4, 128)    512         leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 2, 2, 256)    524544      batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 2, 2, 256)    0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 2, 2, 256)    1024        leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 4, 4, 256)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 4, 4, 128)    524416      up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 4, 4, 128)    512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 4, 4, 256)    0           batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 8, 8, 256)    0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 8, 8, 64)     262208      up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 8, 8, 64)     256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 8, 8, 128)    0           batch_normalization_5[0][0]      \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 16, 16, 128)  0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 32)   65568       up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 32)   128         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 16, 16, 64)   0           batch_normalization_6[0][0]      \n",
      "                                                                 leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 32, 32, 64)   0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 1)    1025        up_sampling2d_4[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,545,025\n",
      "Trainable params: 1,543,681\n",
      "Non-trainable params: 1,344\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# prints a summary representation of your model\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discriminator\n",
    "\n",
    "Our discriminator is a **convolutional neural network** that takes a 28x28 image with 1 channel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T17:17:32.326856Z",
     "start_time": "2018-06-18T17:17:32.275681Z"
    }
   },
   "outputs": [],
   "source": [
    "# Discriminator network\n",
    "k = 4\n",
    "\n",
    "discriminator = Sequential()\n",
    "discriminator.add(Conv2D(64, kernel_size=k, strides=2, padding='same', input_shape=img_shape))\n",
    "discriminator.add(LeakyReLU(alpha=0.8))\n",
    "discriminator.add(Conv2D(128, kernel_size=k, strides=2, padding='same'))\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "discriminator.add(InstanceNormalization())\n",
    "discriminator.add(Conv2D(256, kernel_size=k, strides=2, padding='same'))\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "discriminator.add(InstanceNormalization())\n",
    "\n",
    "img_d = Input(shape=img_shape)\n",
    "features = discriminator(img_d)\n",
    "\n",
    "validity = Conv2D(1, kernel_size=k, strides=1, padding='same')(features)\n",
    "# validity = Flatten()(validity)\n",
    "# validity = Dense(1, activation='sigmoid')(validity)\n",
    "\n",
    "label = Flatten()(features)\n",
    "label = Dense(num_classes+1, activation=\"softmax\")(label)\n",
    "\n",
    "discriminator = Model(img_d, [validity, label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discriminator model visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 32, 32, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 4, 4, 256)    656836      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 4096)         0           sequential_1[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 4, 4, 1)      4097        sequential_1[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 11)           45067       flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 706,000\n",
      "Trainable params: 706,000\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# prints a summary representation of your model\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Compile model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T17:17:32.385813Z",
     "start_time": "2018-06-18T17:17:32.334488Z"
    }
   },
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "\n",
    "discriminator.compile(opt, loss=['mse', 'categorical_crossentropy'],\n",
    "                      loss_weights=[0.5, 0.5],\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combined network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T17:17:32.670427Z",
     "start_time": "2018-06-18T17:17:32.387601Z"
    }
   },
   "outputs": [],
   "source": [
    "# The generator takes noise as input and generates imgs\n",
    "masked_img = Input(shape=(img_shape))\n",
    "gen_img = generator(masked_img)\n",
    "\n",
    "# For the combined model we will only train the generator\n",
    "discriminator.trainable = False\n",
    "\n",
    "validity, _ = discriminator(gen_img)\n",
    "\n",
    "d_g = Model(masked_img, validity)\n",
    "\n",
    "d_g.compile(opt, loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T17:17:32.676287Z",
     "start_time": "2018-06-18T17:17:32.672335Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 32, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 32, 32, 1)         1545025   \n",
      "_________________________________________________________________\n",
      "model_2 (Model)              [(None, 4, 4, 1), (None,  706000    \n",
      "=================================================================\n",
      "Total params: 2,251,025\n",
      "Trainable params: 1,543,681\n",
      "Non-trainable params: 707,344\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# prints a summary representation of your model\n",
    "d_g.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_randomly(imgs, mask_width=10, mask_height=10):\n",
    "    y1 = np.random.randint(0, imgs.shape[1] - mask_height, imgs.shape[0])\n",
    "    y2 = y1 + mask_height\n",
    "    x1 = np.random.randint(0, imgs.shape[2] - mask_width, imgs.shape[0])\n",
    "    x2 = x1 + mask_width\n",
    "\n",
    "    masked_imgs = np.empty_like(imgs)\n",
    "    for i, img in enumerate(imgs):\n",
    "        masked_img = img.copy()\n",
    "        _y1, _y2, _x1, _x2 = y1[i], y2[i], x1[i], x2[i],\n",
    "        masked_img[_y1:_y2, _x1:_x2, :] = 0\n",
    "        masked_imgs[i] = masked_img\n",
    "\n",
    "    return masked_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mask_randomly(X_train[0:1])[0].reshape(32, 32))\n",
    "plt.show()\n",
    "plt.imshow(mask_randomly(X_train[0:1])[0].reshape(32, 32))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Fit model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T17:50:25.368754Z",
     "start_time": "2018-06-18T17:17:32.678615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1/100, batch = 39/937, d_loss=0.547, g_loss=0.428                                                                                                     \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-46252b1bf501>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0md_g_loss_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_g\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         print(\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1218\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1220\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m                                 session)\n\u001b[0;32m-> 2631\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2632\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 64\n",
    "smooth = 0.1\n",
    "\n",
    "\n",
    "# Adversarial ground truths\n",
    "# real = np.ones(shape=(batch_size, 1))\n",
    "# fake = np.zeros(shape=(batch_size, 1))\n",
    "real = np.ones((batch_size, 4, 4, 1))\n",
    "real = real * (1 - smooth)\n",
    "fake = np.zeros((batch_size, 4, 4, 1))\n",
    "\n",
    "fake_labels = to_categorical(np.full((batch_size, 1), num_classes), num_classes=num_classes+1)\n",
    "\n",
    "d_loss = []\n",
    "d_g_loss = []\n",
    "\n",
    "for e in range(epochs + 1):\n",
    "    for i in range(len(X_train) // batch_size):\n",
    "        \n",
    "        # Train Discriminator weights\n",
    "        discriminator.trainable = True\n",
    "        \n",
    "        # Real samples\n",
    "        img_real = X_train[i*batch_size:(i+1)*batch_size]\n",
    "        real_labels = y_train[i*batch_size:(i+1)*batch_size]\n",
    "        \n",
    "        d_loss_real = discriminator.train_on_batch(x=img_real, y=[real, real_labels])\n",
    "        \n",
    "        # Fake Samples\n",
    "        masked_imgs = mask_randomly(img_real)\n",
    "        gen_imgs = generator.predict(masked_imgs)\n",
    "        \n",
    "        d_loss_fake = discriminator.train_on_batch(x=gen_imgs, y=[fake, fake_labels])\n",
    "         \n",
    "        # Discriminator loss\n",
    "        d_loss_batch = 0.5 * (d_loss_real[0] + d_loss_fake[0])\n",
    "        \n",
    "        # Train Generator weights\n",
    "        discriminator.trainable = False\n",
    "\n",
    "        d_g_loss_batch = d_g.train_on_batch(x=img_real, y=real)\n",
    "   \n",
    "        print(\n",
    "            'epoch = %d/%d, batch = %d/%d, d_loss=%.3f, g_loss=%.3f' % (e + 1, epochs, i, len(X_train) // batch_size, d_loss_batch, d_g_loss_batch[0]),\n",
    "            100*' ',\n",
    "            end='\\r'\n",
    "        )\n",
    "    \n",
    "    d_loss.append(d_loss_batch)\n",
    "    d_g_loss.append(d_g_loss_batch[0])\n",
    "    print('epoch = %d/%d, d_loss=%.3f, g_loss=%.3f' % (e + 1, epochs, d_loss[-1], d_g_loss[-1]), 100*' ')\n",
    "\n",
    "    if e % 10 == 0:\n",
    "        samples = 5\n",
    "        idx = np.random.randint(0, X_train.shape[0], samples)\n",
    "        x_fake = generator.predict(X_train[idx])\n",
    "\n",
    "        for k in range(samples):\n",
    "            # plot masked\n",
    "            plt.subplot(2, 5, k+1)\n",
    "            plt.imshow(X_train[idx[k]].reshape(32, 32), cmap='gray')\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "\n",
    "            # plot recontructed\n",
    "            plt.subplot(2, 5, k+6)\n",
    "            plt.imshow(x_fake[k].reshape(32, 32), cmap='gray')\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T17:50:25.534633Z",
     "start_time": "2018-06-18T17:50:25.370944Z"
    }
   },
   "outputs": [],
   "source": [
    "# plotting the metrics\n",
    "plt.plot(d_loss)\n",
    "plt.plot(d_g_loss)\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Discriminator', 'Adversarial'], loc='center right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References\n",
    "\n",
    "* [Semi-Supervised Learning with Context-Conditional Generative Adversarial Networks](https://arxiv.org/pdf/1611.06430.pdf)\n",
    "* [How to Train a GAN? Tips and tricks to make GANs work](https://github.com/soumith/ganhacks)\n",
    "* [THE MNIST DATABASE of handwritten digits](http://yann.lecun.com/exdb/mnist/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
