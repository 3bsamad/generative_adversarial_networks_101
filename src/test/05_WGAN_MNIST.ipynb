{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wasserstein GAN\n",
    "\n",
    "Introduction to **Wasserstein GAN** or WGAN.\n",
    "\n",
    "This notebook is organized as follows:\n",
    "\n",
    "1. **Background**\n",
    "2. **Definition**\n",
    "3. **Training WGAN with MNIST dataset, Keras and TensorFlow**\n",
    "\n",
    "<a href=\"#background\">1. **Background**</a>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a href=\"#background\"></a>1. Background</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Definition\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training WGANs with MNIST dataset,  Keras and TensorFlow\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 1. Load data\n",
    "\n",
    "#### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T00:02:47.400174Z",
     "start_time": "2018-06-19T00:02:46.597063Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T00:02:49.021637Z",
     "start_time": "2018-06-19T00:02:47.402154Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, ReLU, LeakyReLU, BatchNormalization\n",
    "from keras.layers import Conv2D, Conv2DTranspose, Reshape, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import initializers\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T00:02:49.602716Z",
     "start_time": "2018-06-19T00:02:49.023733Z"
    }
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore visual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T00:02:50.191363Z",
     "start_time": "2018-06-19T00:02:49.604723Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    x_y = X_train[y_train == i]\n",
    "    plt.imshow(x_y[0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Class %d\" % (i))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshaping and normalizing the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T00:02:50.646294Z",
     "start_time": "2018-06-19T00:02:50.193290Z"
    }
   },
   "outputs": [],
   "source": [
    "print('X_train.shape', X_train.shape)\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "    input_shape = (1, 28, 28)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "    input_shape = (28, 28, 1)\n",
    "\n",
    "# the generator is using tanh activation, for which we need to preprocess \n",
    "# the image data into the range between -1 and 1.\n",
    "\n",
    "X_train = np.float32(X_train)\n",
    "X_train = (X_train / 255 - 0.5) * 2\n",
    "X_train = np.clip(X_train, -1, 1)\n",
    "\n",
    "print('X_train reshape:', X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define model\n",
    "\n",
    "#### Generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T00:02:51.514030Z",
     "start_time": "2018-06-19T00:02:50.648356Z"
    }
   },
   "outputs": [],
   "source": [
    "# latent space dimension\n",
    "latent_dim = 100\n",
    "\n",
    "# imagem dimension 28x28\n",
    "img_dim = 784\n",
    "\n",
    "# Generator network\n",
    "generator = Sequential()\n",
    "\n",
    "# FC: 7x7x256\n",
    "generator.add(Dense(7*7*256, input_shape=(latent_dim,)))\n",
    "generator.add(Reshape((7, 7, 256)))\n",
    "generator.add(ReLU())\n",
    "\n",
    "# # Conv 1: 14x14x128\n",
    "generator.add(Conv2DTranspose(128, kernel_size=3, strides=2, padding='same'))\n",
    "generator.add(BatchNormalization(momentum=0.8))\n",
    "generator.add(ReLU())\n",
    "\n",
    "# Conv 2: 28x28x64\n",
    "generator.add(Conv2DTranspose(64, kernel_size=3, strides=1, padding='same'))\n",
    "generator.add(BatchNormalization(momentum=0.8))\n",
    "generator.add(ReLU())\n",
    "\n",
    "# Conv 3: 28x28x32\n",
    "generator.add(Conv2DTranspose(32, kernel_size=3, strides=1, padding='same'))\n",
    "generator.add(BatchNormalization(momentum=0.8))\n",
    "generator.add(ReLU())\n",
    "\n",
    "# Conv 4: 28x28x1\n",
    "generator.add(Conv2DTranspose(1, kernel_size=3, strides=2, padding='same',\n",
    "                              activation='tanh'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator model visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T00:02:51.521078Z",
     "start_time": "2018-06-19T00:02:51.516058Z"
    }
   },
   "outputs": [],
   "source": [
    "# prints a summary representation of your model\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Critic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T00:02:51.602831Z",
     "start_time": "2018-06-19T00:02:51.522937Z"
    }
   },
   "outputs": [],
   "source": [
    "# Critic network\n",
    "critic = Sequential()\n",
    "\n",
    "# imagem shape 28x28x1\n",
    "img_shape = X_train[0].shape\n",
    "\n",
    "# Conv 1: 14x14x64\n",
    "critic.add(Conv2D(32, kernel_size=3, strides=2, padding='same',\n",
    "                  input_shape=(img_shape)))\n",
    "critic.add(LeakyReLU(0.2))\n",
    "\n",
    "# Conv 2:\n",
    "critic.add(Conv2D(64, kernel_size=3, strides=2, padding='same'))\n",
    "critic.add(BatchNormalization(momentum=0.8))\n",
    "critic.add(LeakyReLU(0.2))\n",
    "\n",
    "# Conv 3: \n",
    "critic.add(Conv2D(128, kernel_size=3, strides=2, padding='same'))\n",
    "critic.add(BatchNormalization(momentum=0.8))\n",
    "critic.add(LeakyReLU(0.2))\n",
    "\n",
    "# Conv 4: \n",
    "critic.add(Conv2D(512, kernel_size=3, strides=1, padding='same'))\n",
    "critic.add(BatchNormalization(momentum=0.8))\n",
    "critic.add(LeakyReLU(0.2))\n",
    "\n",
    "# FC\n",
    "critic.add(Flatten())\n",
    "\n",
    "# Output\n",
    "critic.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Critic model visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T00:02:51.608924Z",
     "start_time": "2018-06-19T00:02:51.604651Z"
    }
   },
   "outputs": [],
   "source": [
    "# prints a summary representation of your model\n",
    "critic.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Compile model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T00:02:51.697630Z",
     "start_time": "2018-06-19T00:02:51.611026Z"
    }
   },
   "outputs": [],
   "source": [
    "# Following parameter and optimizer set as recommended in paper\n",
    "n_critic = 5\n",
    "clip_value = 0.01\n",
    "optimizer = RMSprop(lr=0.00005)\n",
    "\n",
    "critic.compile(optimizer=optimizer, loss=wasserstein_loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combined network\n",
    "\n",
    "We connect the generator and the critic to make a WGAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T00:02:52.080923Z",
     "start_time": "2018-06-19T00:02:51.699590Z"
    }
   },
   "outputs": [],
   "source": [
    "critic.trainable = False\n",
    "\n",
    "z = Input(shape=(latent_dim,))\n",
    "img = generator(z)\n",
    "valid = critic(img)\n",
    "d_g = Model(inputs=z, outputs=valid, name='wgan')\n",
    "\n",
    "d_g.compile(optimizer=optimizer, loss=wasserstein_loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GAN model vizualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T00:02:52.087799Z",
     "start_time": "2018-06-19T00:02:52.083174Z"
    }
   },
   "outputs": [],
   "source": [
    "# prints a summary representation of your model\n",
    "d_g.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Fit model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T02:02:33.125417Z",
     "start_time": "2018-06-19T00:02:52.089965Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 64\n",
    "\n",
    "real = -np.ones(shape=(batch_size, 1))\n",
    "fake = np.ones(shape=(batch_size, 1))\n",
    "\n",
    "d_loss = []\n",
    "g_loss = []\n",
    "\n",
    "for e in range(epochs + 1):\n",
    "    for i in range(len(X_train) // batch_size):\n",
    "        for _ in range(n_critic):\n",
    "\n",
    "            # Train Discriminator weights\n",
    "            critic.trainable = True\n",
    "\n",
    "            # Real samples\n",
    "            X_batch = X_train[i*batch_size:(i+1)*batch_size]\n",
    "            d_loss_real = critic.train_on_batch(X_batch, -np.ones(X_batch.shape[0]))\n",
    "\n",
    "            # Fake Samples\n",
    "            z = np.random.normal(loc=0, scale=1, size=(batch_size, latent_dim))\n",
    "            X_fake = generator.predict(z)\n",
    "            d_loss_fake = critic.train_on_batch(X_fake, np.ones(X_fake.shape[0]))\n",
    "\n",
    "            # Discriminator loss\n",
    "            d_loss_batch = 0.5 * (d_loss_real[0] + d_loss_fake[0])\n",
    "\n",
    "            # Clip critic weights\n",
    "            for l in critic.layers:\n",
    "                weights = l.get_weights()\n",
    "                weights = [np.clip(w, -clip_value, clip_value) for w in weights]\n",
    "                l.set_weights(weights)\n",
    "\n",
    "        # Train Generator weights\n",
    "        critic.trainable = False\n",
    "        g_loss_batch = d_g.train_on_batch(z, -np.ones(z.shape[0]))\n",
    "\n",
    "        print(\n",
    "            'epoch = %d/%d, batch = %d/%d, d_loss=%.3f, g_loss=%.3f' % (e + 1, epochs, i, len(X_train) // batch_size, d_loss_batch, g_loss_batch[0]),\n",
    "            100*' ',\n",
    "            end='\\r'\n",
    "        )\n",
    "    \n",
    "    d_loss.append(d_loss_batch)\n",
    "    g_loss.append(g_loss_batch[0])\n",
    "    print('epoch = %d/%d, d_loss=%.3f, g_loss=%.3f' % (e + 1, epochs, d_loss[-1], g_loss[-1]), 100*' ')\n",
    "\n",
    "    if e % 10 == 0:\n",
    "        samples = 10\n",
    "        x_fake = generator.predict(np.random.normal(loc=0, scale=1, size=(samples, latent_dim)))\n",
    "\n",
    "        for k in range(samples):\n",
    "            plt.subplot(2, 5, k+1)\n",
    "            plt.imshow(x_fake[k].reshape(28, 28), cmap='gray')\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T02:02:33.284689Z",
     "start_time": "2018-06-19T02:02:33.127648Z"
    }
   },
   "outputs": [],
   "source": [
    "# plotting the metrics\n",
    "plt.plot(d_loss)\n",
    "plt.plot(g_loss)\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Discriminator', 'Adversarial'], loc='center right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* [Wasserstein GAN](https://arxiv.org/pdf/1701.07875.pdf)\n",
    "* [THE MNIST DATABASE of handwritten digits](http://yann.lecun.com/exdb/mnist/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
